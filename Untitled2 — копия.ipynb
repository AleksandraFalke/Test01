{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVING_FRAMES_PER_SECOND = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(td):\n",
    "    result = str(td)\n",
    "    try:\n",
    "        result, ms = result.split(\".\")\n",
    "    except ValueError:\n",
    "        return result + \".00\".replace(\":\", \"-\")\n",
    "    ms = int(ms)\n",
    "    ms = round(ms / 1e4)\n",
    "    return f\"{result}.{ms:02}\".replace(\":\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames(cap, saving_fps):\n",
    "    s = []\n",
    "    clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
    "    for i in np.arange(0, clip_duration, 1 / saving_fps):\n",
    "        s.append(i)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pure(copy):\n",
    "    \n",
    "    filename, _ = os.path.splitext(copy)\n",
    "    filename += \"-cv\"\n",
    "    \n",
    "    if not os.path.isdir(filename):\n",
    "        os.mkdir(filename)   \n",
    "    cap = cv2.VideoCapture(copy)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    saving_frames_per_second = min(fps, SAVING_FRAMES_PER_SECOND)\n",
    "    saving_frames_durations = frames(cap, saving_frames_per_second)\n",
    "    count = 0\n",
    "    while True:\n",
    "        is_read, frame = cap.read()\n",
    "        if not is_read:\n",
    "            break\n",
    "        frame_duration = count / fps\n",
    "        try:\n",
    "            closest_duration = saving_frames_durations[0]\n",
    "        except IndexError:\n",
    "            break\n",
    "        if frame_duration >= closest_duration:\n",
    "            frame_duration_formatted = delta(timedelta(seconds=frame_duration))\n",
    "            cv2.imwrite(os.path.join(filename, f\"frame{frame_duration_formatted}.jpg\"), frame) \n",
    "            try:\n",
    "                saving_frames_durations.pop(0)\n",
    "            except IndexError:\n",
    "                pass\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich.mp4\n"
     ]
    }
   ],
   "source": [
    "data = [f for f in os.listdir('../../Test003/AAA1/') if os.path.isfile(f) and f.endswith(\".mp4\")]\n",
    "print(data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    copy = sys.argv[1]\n",
    "    Pure(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_lip = []\n",
    "images = os.listdir('../../Test003/AAA1/' + \"/\" + \"ich-cv\")\n",
    "for i in range(len(images)):\n",
    "    img = cv2.imread('../../Test003/AAA1/' + \"/\" + \"ich-cv\" + \"/\" + images[i])\n",
    "    images_lip.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGG = [t.detach().numpy() for t in IMAGE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nop = []\n",
    "IMAGE = []\n",
    "for i in range(len(images_lip)):\n",
    "    nop = np.hstack(images_lip[i])\n",
    "    IMAGE.append(torch.FloatTensor(nop))\n",
    "    nop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nop = []\n",
    "IMAGE = []\n",
    "for i in range(len(images_lip)):\n",
    "    nop = np.array(images_lip[i])\n",
    "    IMAGE.append(torch.FloatTensor(nop))\n",
    "    nop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nop = []\n",
    "IMAGE = []\n",
    "for i in range(len(images_lip)):\n",
    "    nop = images_lip[i]\n",
    "    IMAGE.append(nop)\n",
    "    nop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[180, 202, 244],\n",
       "        [179, 201, 243],\n",
       "        [176, 200, 242],\n",
       "        ...,\n",
       "        [161, 207, 238],\n",
       "        [161, 207, 238],\n",
       "        [161, 207, 238]],\n",
       "\n",
       "       [[180, 202, 244],\n",
       "        [177, 201, 243],\n",
       "        [175, 199, 241],\n",
       "        ...,\n",
       "        [161, 207, 238],\n",
       "        [161, 207, 238],\n",
       "        [161, 207, 238]],\n",
       "\n",
       "       [[177, 202, 242],\n",
       "        [175, 201, 241],\n",
       "        [174, 200, 240],\n",
       "        ...,\n",
       "        [161, 207, 238],\n",
       "        [161, 207, 238],\n",
       "        [161, 207, 238]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 24,  35,  62],\n",
       "        [ 24,  35,  62],\n",
       "        [ 25,  36,  63],\n",
       "        ...,\n",
       "        [131, 175, 234],\n",
       "        [132, 176, 235],\n",
       "        [132, 176, 235]],\n",
       "\n",
       "       [[ 24,  35,  62],\n",
       "        [ 24,  35,  62],\n",
       "        [ 25,  36,  63],\n",
       "        ...,\n",
       "        [131, 175, 234],\n",
       "        [132, 176, 235],\n",
       "        [132, 176, 235]],\n",
       "\n",
       "       [[ 23,  34,  61],\n",
       "        [ 24,  35,  62],\n",
       "        [ 25,  36,  63],\n",
       "        ...,\n",
       "        [131, 175, 234],\n",
       "        [132, 176, 235],\n",
       "        [132, 176, 235]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_lip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_lip = []\n",
    "lip_plop = []\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "images = os.listdir('../../Test003/AAA1/' + \"/\" + \"ich-cv\")\n",
    "for k in range(len(images)):\n",
    "    img = cv2.imread('../../Test003/AAA1/' + \"/\" + \"ich-cv\" + \"/\" + images[k])\n",
    "    gray = cv2.cvtColor(src=img, code=cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        x1 = face.left()\n",
    "        y1 = face.top() \n",
    "        x2 = face.right() \n",
    "        y2 = face.bottom()\n",
    "        landmarks = predictor(image=gray, box=face)    \n",
    "        for n in range(48, 68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            name = (x,y)\n",
    "            lip_plop.append(name)\n",
    "        dot_lip.append(lip_plop)\n",
    "        lip_plop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd = [1,2,1,2,3,3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['frames','label','abc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['frames'] = images_lip\n",
    "df['label'] = dot_lip\n",
    "df['abc'] = abcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frames</th>\n",
       "      <th>label</th>\n",
       "      <th>abc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[180, 202, 244], [179, 201, 243], [176, 200,...</td>\n",
       "      <td>[(609, 520), (634, 504), (656, 495), (672, 499...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[132, 195, 255], [132, 195, 255], [133, 195,...</td>\n",
       "      <td>[(611, 524), (633, 504), (656, 493), (671, 497...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[139, 200, 240], [139, 200, 240], [139, 200,...</td>\n",
       "      <td>[(609, 522), (634, 506), (656, 496), (671, 500...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[145, 193, 241], [145, 193, 241], [144, 192,...</td>\n",
       "      <td>[(613, 522), (635, 503), (656, 493), (672, 496...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[147, 206, 246], [143, 204, 244], [138, 203,...</td>\n",
       "      <td>[(610, 518), (635, 504), (656, 495), (671, 499...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[[140, 202, 238], [141, 201, 237], [143, 201,...</td>\n",
       "      <td>[(608, 517), (633, 504), (655, 494), (670, 498...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[[164, 201, 239], [164, 201, 239], [162, 201,...</td>\n",
       "      <td>[(607, 517), (633, 504), (655, 495), (670, 499...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              frames  \\\n",
       "0  [[[180, 202, 244], [179, 201, 243], [176, 200,...   \n",
       "1  [[[132, 195, 255], [132, 195, 255], [133, 195,...   \n",
       "2  [[[139, 200, 240], [139, 200, 240], [139, 200,...   \n",
       "3  [[[145, 193, 241], [145, 193, 241], [144, 192,...   \n",
       "4  [[[147, 206, 246], [143, 204, 244], [138, 203,...   \n",
       "5  [[[140, 202, 238], [141, 201, 237], [143, 201,...   \n",
       "6  [[[164, 201, 239], [164, 201, 239], [162, 201,...   \n",
       "\n",
       "                                               label  abc  \n",
       "0  [(609, 520), (634, 504), (656, 495), (672, 499...    1  \n",
       "1  [(611, 524), (633, 504), (656, 493), (671, 497...    2  \n",
       "2  [(609, 522), (634, 506), (656, 496), (671, 500...    1  \n",
       "3  [(613, 522), (635, 503), (656, 493), (672, 496...    2  \n",
       "4  [(610, 518), (635, 504), (656, 495), (671, 499...    3  \n",
       "5  [(608, 517), (633, 504), (655, 494), (670, 498...    3  \n",
       "6  [(607, 517), (633, 504), (655, 495), (670, 499...    3  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# м-1\n",
    "# а-2\n",
    "# ?-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam = dot_lip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bam)):\n",
    "    bam[i].append(abcd[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(609, 520),\n",
       " (634, 504),\n",
       " (656, 495),\n",
       " (672, 499),\n",
       " (688, 495),\n",
       " (709, 503),\n",
       " (733, 517),\n",
       " (709, 532),\n",
       " (689, 537),\n",
       " (672, 539),\n",
       " (656, 537),\n",
       " (634, 532),\n",
       " (621, 519),\n",
       " (655, 511),\n",
       " (672, 512),\n",
       " (687, 511),\n",
       " (723, 517),\n",
       " (688, 518),\n",
       " (672, 519),\n",
       " (656, 517),\n",
       " 1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bam[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns = ['frames','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['frames'] = images_lip\n",
    "df2['label'] = dot_lip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frames</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[180, 202, 244], [179, 201, 243], [176, 200,...</td>\n",
       "      <td>[(609, 520), (634, 504), (656, 495), (672, 499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[132, 195, 255], [132, 195, 255], [133, 195,...</td>\n",
       "      <td>[(611, 524), (633, 504), (656, 493), (671, 497...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[139, 200, 240], [139, 200, 240], [139, 200,...</td>\n",
       "      <td>[(609, 522), (634, 506), (656, 496), (671, 500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[145, 193, 241], [145, 193, 241], [144, 192,...</td>\n",
       "      <td>[(613, 522), (635, 503), (656, 493), (672, 496...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[147, 206, 246], [143, 204, 244], [138, 203,...</td>\n",
       "      <td>[(610, 518), (635, 504), (656, 495), (671, 499...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              frames  \\\n",
       "0  [[[180, 202, 244], [179, 201, 243], [176, 200,...   \n",
       "1  [[[132, 195, 255], [132, 195, 255], [133, 195,...   \n",
       "2  [[[139, 200, 240], [139, 200, 240], [139, 200,...   \n",
       "3  [[[145, 193, 241], [145, 193, 241], [144, 192,...   \n",
       "4  [[[147, 206, 246], [143, 204, 244], [138, 203,...   \n",
       "\n",
       "                                               label  \n",
       "0  [(609, 520), (634, 504), (656, 495), (672, 499...  \n",
       "1  [(611, 524), (633, 504), (656, 493), (671, 497...  \n",
       "2  [(609, 522), (634, 506), (656, 496), (671, 500...  \n",
       "3  [(613, 522), (635, 503), (656, 493), (672, 496...  \n",
       "4  [(610, 518), (635, 504), (656, 495), (671, 499...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[[[180 202 244], [179 201 243], [176 200 242]...\n",
       "1    [[[[132 195 255], [132 195 255], [133 195 255]...\n",
       "2    [[[[139 200 240], [139 200 240], [139 200 240]...\n",
       "3    [[[[145 193 241], [145 193 241], [144 192 240]...\n",
       "4    [[[[147 206 246], [143 204 244], [138 203 242]...\n",
       "5    [[[[140 202 238], [141 201 237], [143 201 237]...\n",
       "6    [[[[164 201 239], [164 201 239], [162 201 239]...\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_lip_2 = []\n",
    "images = os.listdir('../../Test003/AAA1/' + \"/\" + \"ich-cv\")\n",
    "readPath = r'../../Test003/AAA1/' + \"/\" + \"ich-cv\"\n",
    "for i in range(len(images)):\n",
    "    image = Image.open(readPath + \"/\" + images[i])\n",
    "    transform = transforms.ToTensor()\n",
    "    images_lip_2.append(transform(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9569, 0.9529, 0.9490,  ..., 0.9333, 0.9333, 0.9333],\n",
       "         [0.9569, 0.9529, 0.9451,  ..., 0.9333, 0.9333, 0.9333],\n",
       "         [0.9529, 0.9490, 0.9451,  ..., 0.9333, 0.9333, 0.9333],\n",
       "         ...,\n",
       "         [0.2431, 0.2431, 0.2471,  ..., 0.9176, 0.9216, 0.9216],\n",
       "         [0.2431, 0.2431, 0.2471,  ..., 0.9176, 0.9216, 0.9216],\n",
       "         [0.2392, 0.2431, 0.2471,  ..., 0.9176, 0.9216, 0.9216]],\n",
       "\n",
       "        [[0.7882, 0.7882, 0.7843,  ..., 0.8118, 0.8118, 0.8118],\n",
       "         [0.7922, 0.7882, 0.7804,  ..., 0.8118, 0.8118, 0.8118],\n",
       "         [0.7882, 0.7843, 0.7804,  ..., 0.8118, 0.8118, 0.8118],\n",
       "         ...,\n",
       "         [0.1373, 0.1373, 0.1412,  ..., 0.6863, 0.6902, 0.6902],\n",
       "         [0.1373, 0.1373, 0.1412,  ..., 0.6863, 0.6902, 0.6902],\n",
       "         [0.1333, 0.1373, 0.1412,  ..., 0.6863, 0.6902, 0.6902]],\n",
       "\n",
       "        [[0.7137, 0.7020, 0.6902,  ..., 0.6314, 0.6314, 0.6314],\n",
       "         [0.7059, 0.7020, 0.6863,  ..., 0.6314, 0.6314, 0.6314],\n",
       "         [0.6941, 0.6902, 0.6824,  ..., 0.6314, 0.6314, 0.6314],\n",
       "         ...,\n",
       "         [0.0941, 0.0941, 0.0980,  ..., 0.5137, 0.5176, 0.5176],\n",
       "         [0.0941, 0.0941, 0.0980,  ..., 0.5137, 0.5176, 0.5176],\n",
       "         [0.0902, 0.0941, 0.1059,  ..., 0.5137, 0.5176, 0.5176]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_lip_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "plop = []\n",
    "nana_2 = []\n",
    "for i in range(len(dot_lip)):\n",
    "    plop = np.hstack(dot_lip[i])\n",
    "    nana_2.append(torch.FloatTensor(plop))\n",
    "    plop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([609., 520., 634., 504., 656., 495., 672., 499., 688., 495., 709., 503.,\n",
       "         733., 517., 709., 532., 689., 537., 672., 539., 656., 537., 634., 532.,\n",
       "         621., 519., 655., 511., 672., 512., 687., 511., 723., 517., 688., 518.,\n",
       "         672., 519., 656., 517.,   1.]),\n",
       " tensor([611., 524., 633., 504., 656., 493., 671., 497., 687., 493., 709., 504.,\n",
       "         729., 524., 708., 545., 687., 554., 670., 556., 654., 553., 632., 544.,\n",
       "         623., 523., 655., 510., 671., 512., 686., 511., 718., 524., 686., 532.,\n",
       "         671., 533., 655., 531.,   2.]),\n",
       " tensor([609., 522., 634., 506., 656., 496., 671., 500., 685., 495., 707., 504.,\n",
       "         730., 518., 706., 534., 687., 542., 671., 544., 655., 542., 634., 535.,\n",
       "         621., 521., 655., 511., 671., 513., 685., 511., 719., 518., 686., 522.,\n",
       "         671., 523., 656., 521.,   1.]),\n",
       " tensor([613., 522., 635., 503., 656., 493., 672., 496., 687., 492., 709., 502.,\n",
       "         731., 518., 708., 535., 688., 542., 672., 544., 656., 543., 635., 536.,\n",
       "         625., 521., 656., 508., 672., 509., 687., 508., 720., 518., 687., 523.,\n",
       "         672., 524., 656., 523.,   2.]),\n",
       " tensor([610., 518., 635., 504., 656., 495., 671., 499., 686., 495., 708., 502.,\n",
       "         732., 513., 708., 527., 687., 534., 672., 535., 656., 534., 635., 529.,\n",
       "         621., 517., 656., 510., 671., 512., 686., 511., 722., 514., 687., 516.,\n",
       "         672., 517., 657., 515.,   3.]),\n",
       " tensor([608., 517., 633., 504., 655., 494., 670., 498., 685., 493., 707., 501.,\n",
       "         732., 510., 707., 523., 687., 530., 671., 532., 655., 531., 634., 527.,\n",
       "         619., 516., 655., 510., 670., 512., 685., 509., 722., 511., 685., 513.,\n",
       "         671., 515., 656., 513.,   3.]),\n",
       " tensor([607., 517., 633., 504., 655., 495., 670., 499., 685., 495., 706., 501.,\n",
       "         731., 511., 706., 525., 687., 531., 671., 533., 655., 532., 633., 527.,\n",
       "         619., 516., 654., 510., 670., 512., 685., 510., 720., 512., 686., 514.,\n",
       "         671., 516., 656., 514.,   3.])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nana_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(IMAGE, nana_2,  test_size=0.3,  random_state = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.float()\n",
    "#X_test = X_test.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.dtype, X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = np.array(y_test)\n",
    "#y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = y_test.float()\n",
    "#y_train = y_train.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "X_train = np.true_divide(X_train, 255.)\n",
    "X_test = np.true_divide(X_test, 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vop = X_train.unsqueeze(-1)\n",
    "#X_test = X_test.unsqueeze(-1)\n",
    "#vop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 720, 1280, 3]), torch.Size([3, 720, 1280, 3]))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
